{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai import data, transforms\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import natsort\n",
    "import SimpleITK as sitk\n",
    "\n",
    "def get_loader():\n",
    "    train_real = natsort.natsorted(glob.glob(f'/workspace/PD_SSL_ZOO/3_RECONSTRUCTION/DATA/*.nii.gz'))[:] #ALL -> 2125 or 2130\n",
    "\n",
    "    print(\"Train [Total]  number = \", len(train_real))\n",
    "\n",
    "    files_tr = [img_tr for img_tr in zip(train_real)]\n",
    "\n",
    "    tr_transforms = transforms.Compose(\n",
    "        [\n",
    "            transforms.LoadImage(image_only=True),\n",
    "            transforms.EnsureChannelFirst(),\n",
    "            transforms.Orientation(axcodes=\"RAI\"),\n",
    "            transforms.EnsureType(),\n",
    "            transforms.ToTensor(track_meta=False)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # new_dataset -> Cachenew_dataset\n",
    "    train_ds = data.Dataset(data = files_tr, transform = tr_transforms)\n",
    "\n",
    "    train_loader = data.DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        pin_memory=False\n",
    "        # persistent_workers=True,\n",
    "    )\n",
    "\n",
    "    print(\"loader is ver (train)\")\n",
    "\n",
    "    loader = train_loader\n",
    "\n",
    "    return loader, train_real\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from generative.networks.nets.diffusion_model_aniso_unet_AE_no_wavelet import DiffusionModelUNet_aniso_AE_no_wavelet, DiffusionModelEncoder_ansio_no_wavelet\n",
    "\n",
    "class HDAE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.unet =  DiffusionModelUNet_aniso_AE_no_wavelet(spatial_dims=3,\n",
    "                                                            in_channels=1, \n",
    "                                                            out_channels=1, \n",
    "                                                            num_channels=[8,32,64,128,256,512],\n",
    "                                                            attention_levels=[False,False,False,False,True,True],\n",
    "                                                            num_head_channels=[0,0,0,0,16,32],\n",
    "                                                            norm_num_groups=8,\n",
    "                                                            use_flash_attention=True,\n",
    "                                                            iso_conv_down=(False, True, True, True, True, None),\n",
    "                                                            iso_conv_up=(True, True, True, True, False, None),\n",
    "                                                            num_res_blocks=2,)\n",
    "\n",
    "\n",
    "        self.semantic_encoder = DiffusionModelEncoder_ansio_no_wavelet(spatial_dims=3,\n",
    "                                                                        in_channels=1,\n",
    "                                                                        out_channels=1,\n",
    "                                                                        num_channels=[16,32,128,256,512],\n",
    "                                                                        attention_levels=(False,False,False,False,False),\n",
    "                                                                        num_head_channels=[0,0,0,0,0],\n",
    "                                                                        norm_num_groups=16,\n",
    "                                                                        iso_conv_down=(False, True, True, True, True),\n",
    "                                                                        resblock_updown=False,\n",
    "                                                                        num_res_blocks=(2,2,2,2,2))\n",
    "\n",
    "def filter_ema_keys(checkpoint):\n",
    "    ema_model_state_dict = {key.replace('ema_model.', ''): value \n",
    "                            for key, value in checkpoint.items() \n",
    "                            if 'online_model' not in key}\n",
    "    del ema_model_state_dict['initted']\n",
    "    del ema_model_state_dict['step']\n",
    "    \n",
    "    return ema_model_state_dict\n",
    "\n",
    "def save_image(pred, path):\n",
    "    pred_img = pred.cpu().detach().numpy().transpose(0,4,3,2,1).squeeze()\n",
    "    pred_img = np.flipud(pred_img)\n",
    "    pred_img = np.fliplr(pred_img)\n",
    "    pred_img = np.flip(pred_img, axis=2)\n",
    "\n",
    "    save_pred = sitk.GetImageFromArray(pred_img)\n",
    "    sitk.WriteImage(save_pred, path)\n",
    "    \n",
    "model = HDAE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(pred, path):\n",
    "    pred_img = pred.cpu().detach().numpy().transpose(0,4,3,2,1).squeeze()\n",
    "    pred_img = np.flipud(pred_img)\n",
    "    pred_img = np.fliplr(pred_img)\n",
    "    save_pred = sitk.GetImageFromArray(pred_img)\n",
    "    sitk.WriteImage(save_pred, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from generative.networks.schedulers import DDPMScheduler\n",
    "from generative.inferers import DiffusionInferer_ae\n",
    "import pywt\n",
    "import ptwt\n",
    "\n",
    "a_path = '/workspace/PD_SSL_ZOO/2_DOWNSTREAM/WEIGHTS/6_HDAE.pt'\n",
    "ckpt = torch.load(a_path, map_location='cpu')\n",
    "checkpoint = ckpt['ema']\n",
    "new_ckpt = filter_ema_keys(checkpoint)\n",
    "model.load_state_dict(new_ckpt)\n",
    "print(f\"ckpt_path : {a_path}\")\n",
    "\n",
    "scheduler = DDPMScheduler(prediction_type=\"epsilon\",\n",
    "                          num_train_timesteps=1000, \n",
    "                          clip_sample=True,\n",
    "                          schedule=\"scaled_linear_beta\")\n",
    "\n",
    "inferer = DiffusionInferer_ae(scheduler)\n",
    "\n",
    "model.to('cuda')\n",
    "loader, train_list = get_loader()\n",
    "\n",
    "for idx, batch in enumerate(loader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        images = batch.to('cuda')\n",
    "        timesteps = torch.randint(0, inferer.scheduler.num_train_timesteps, (images.shape[0],)).to('cuda').long()\n",
    "        latent = model.semantic_encoder(images)\n",
    "\n",
    "    _, _, H, W, D = images.shape\n",
    "    # Sampling image during training\n",
    "    image = torch.randn((1, 1, H, W, D))\n",
    "    image = image.to(\"cuda\")\n",
    "    scheduler.set_timesteps(num_inference_steps=1000)\n",
    "    image_pred = inferer.sample(input_noise=image, \n",
    "                                diffusion_model=model.unet, \n",
    "                                scheduler=scheduler, \n",
    "                                save_intermediates=False,\n",
    "                                cond=latent)\n",
    "        \n",
    "    pred_path = train_list[idx].replace(\"DATA\", \"6_HDAE\")\n",
    "    \n",
    "    save_image(image_pred, pred_path)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
