{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3614530b-60f9-4d83-8499-f58f341ab4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from generative.networks.nets.diffusion_model_aniso_unet_AE_official import DiffusionModelUNet_aniso_AE, DiffusionModelEncoder_ansio\n",
    "import torch\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "from monai import data, transforms\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "import ptwt\n",
    "import pywt\n",
    "import random\n",
    "\n",
    "class DIF_oriAE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.unet =  DiffusionModelUNet_aniso_AE(spatial_dims=3,\n",
    "                                                in_channels=8,\n",
    "                                                out_channels=8,\n",
    "                                                num_channels=[128,128,256,256,512],\n",
    "                                                attention_levels=[False,False,False,False,True],\n",
    "                                                num_head_channels=[0,0,0,0,64],\n",
    "                                                norm_num_groups=32,\n",
    "                                                use_flash_attention=True,\n",
    "                                                iso_conv_down=(False, True, True, True, None),\n",
    "                                                iso_conv_up=(True, True, True, False, None),\n",
    "                                                num_res_blocks=2)\n",
    "\n",
    "        self.semantic_encoder = DiffusionModelEncoder_ansio(spatial_dims=3,\n",
    "                                                            in_channels=8,\n",
    "                                                            out_channels=8,\n",
    "                                                            num_channels=[128,256,256,512],\n",
    "                                                            attention_levels=[False,False,False,False],\n",
    "                                                            num_head_channels=[0,0,0,0],\n",
    "                                                            norm_num_groups=32,\n",
    "                                                            iso_conv_down=(False, True, True, True),\n",
    "                                                            num_res_blocks=(2,2,2,2))\n",
    "\n",
    "model = DIF_oriAE()\n",
    "\n",
    "def filter_ema_keys(checkpoint):\n",
    "    ema_model_state_dict = {key.replace('ema_model.', ''): value \n",
    "                            for key, value in checkpoint.items() \n",
    "                            if 'online_model' not in key}\n",
    "    del ema_model_state_dict['initted']\n",
    "    del ema_model_state_dict['step']\n",
    "    \n",
    "    return ema_model_state_dict\n",
    "\n",
    "ckpt_path = '/workspace/PD_SSL_ZOO/2_DOWNSTREAM/WEIGHTS/1_HWDAE.pt'\n",
    "\n",
    "print(f\"ckpt_path : {ckpt_path}\")\n",
    "ckpt = torch.load(ckpt_path, map_location='cpu')\n",
    "new_ckpt = filter_ema_keys(ckpt['ema'])\n",
    "model.load_state_dict(new_ckpt, strict=False)\n",
    "\n",
    "model = model.to('cuda')\n",
    "\n",
    "def mean_gen_latent(tsne_dataset_gen):\n",
    "    sum_tensors = [torch.zeros_like(tsne_dataset_gen[0][i]) for i in range(len(tsne_dataset_gen[0]))]\n",
    "    \n",
    "    for tensor_list in tsne_dataset_gen:\n",
    "        for i, tensor in enumerate(tensor_list):\n",
    "            sum_tensors[i] += tensor\n",
    "    \n",
    "    mean_tensors = [sum_tensor / len(tsne_dataset_gen) for sum_tensor in sum_tensors]\n",
    "\n",
    "    return mean_tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96635eae-a591-4922-b042-1175ba27eb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Mean Vectors\n",
    "##########################################################################################\n",
    "##########################################################################################\n",
    "'''\n",
    "From This Cell, I try to get MEAN VECTORS of\n",
    "1. NC_LESS\n",
    "2. LESS_MORE\n",
    "3. LESS_NC\n",
    "4. MORE_LESS\n",
    "'''\n",
    "##########################################################################################\n",
    "##########################################################################################\n",
    "\n",
    "def get_loader_for_direc_vector():\n",
    "    \n",
    "    train_list = f\"/workspace/Ablation/ABLATION_PD/INTERPRETATION/JSON/NP/NC_03.json\"\n",
    "    num_class = 1\n",
    "    \n",
    "    train_idx = 0\n",
    "    files_tr_nc = []\n",
    "    \n",
    "    with open(train_list, 'r') as train_file:\n",
    "        train_files = json.load(train_file)\n",
    "        \n",
    "    for file_name, label in train_files['train'].items():\n",
    "        label = torch.nn.functional.one_hot(torch.as_tensor(label), num_classes=num_class)\n",
    "        files_tr_nc.append({\"image_train\": file_name, \"label_train\": label})\n",
    "        train_idx += 1\n",
    "        \n",
    "    files_tr_nc_1 = random.choices(files_tr_nc, k=100)\n",
    "    files_tr_nc_2 = random.choices(files_tr_nc, k=100)\n",
    "    files_tr_nc_3 = random.choices(files_tr_nc, k=100)\n",
    "    files_tr_nc_4 = random.choices(files_tr_nc, k=100)\n",
    "    files_tr_nc_5 = random.choices(files_tr_nc, k=100)\n",
    "    \n",
    "    ##########################################################################################\n",
    "    ##########################################################################################\n",
    "    \n",
    "    train_list = f\"/workspace/Ablation/ABLATION_PD/INTERPRETATION/JSON/REG/ONSET_mean.json\"\n",
    "    num_class = 25\n",
    "    \n",
    "    with open(train_list, 'r') as train_file:\n",
    "        train_files = json.load(train_file)\n",
    "    \n",
    "    files_tr_less = []\n",
    "    files_tr_more = []\n",
    "\n",
    "    for file_name, label in train_files['train'].items():\n",
    "        if label < 5:\n",
    "            label = torch.nn.functional.one_hot(torch.as_tensor(label), num_classes=num_class)\n",
    "            files_tr_less.append({\"image_train\": file_name, \"label_train\": label})\n",
    "            train_idx += 1\n",
    "        else:\n",
    "            label = torch.nn.functional.one_hot(torch.as_tensor(label), num_classes=num_class)\n",
    "            files_tr_more.append({\"image_train\": file_name, \"label_train\": label})\n",
    "            train_idx += 1\n",
    "\n",
    "    files_tr_less_1 = random.choices(files_tr_less, k=100)\n",
    "    files_tr_less_2 = random.choices(files_tr_less, k=100)\n",
    "    files_tr_less_3 = random.choices(files_tr_less, k=100)\n",
    "    files_tr_less_4 = random.choices(files_tr_less, k=100)\n",
    "    files_tr_less_5 = random.choices(files_tr_less, k=100)\n",
    "    \n",
    "    files_tr_more_1 = random.choices(files_tr_more, k=100)\n",
    "    files_tr_more_2 = random.choices(files_tr_more, k=100)\n",
    "    files_tr_more_3 = random.choices(files_tr_more, k=100)\n",
    "    files_tr_more_4 = random.choices(files_tr_more, k=100)\n",
    "    files_tr_more_5 = random.choices(files_tr_more, k=100)\n",
    "    \n",
    "    print(\"Train [Total]  number = \", train_idx)\n",
    "\n",
    "    tr_transforms = transforms.Compose(\n",
    "        [\n",
    "            transforms.LoadImaged(keys=[\"image_train\"]),\n",
    "            transforms.EnsureChannelFirstd(keys=[\"image_train\"]),\n",
    "            transforms.Orientationd(keys=[\"image_train\"], axcodes=\"LPS\"),\n",
    "            transforms.ScaleIntensityRanged(keys=[\"image_train\"], a_min=0.0, a_max=22.0, b_min=0.0, b_max=1.0, clip=True),\n",
    "            transforms.EnsureTyped(keys=[\"image_train\", \"label_train\"]),\n",
    "            transforms.ToTensord(keys=[\"image_train\", \"label_train\"], track_meta=False)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # new_dataset -> Cachenew_dataset\n",
    "    train_ds_nc_1 = data.Dataset(data = files_tr_nc_1, transform = tr_transforms)\n",
    "    train_ds_nc_2 = data.Dataset(data = files_tr_nc_2, transform = tr_transforms)\n",
    "    train_ds_nc_3 = data.Dataset(data = files_tr_nc_3, transform = tr_transforms)\n",
    "    train_ds_nc_4 = data.Dataset(data = files_tr_nc_4, transform = tr_transforms)\n",
    "    train_ds_nc_5 = data.Dataset(data = files_tr_nc_5, transform = tr_transforms)\n",
    "    \n",
    "    files_tr_less_1 = data.Dataset(data = files_tr_less_1, transform = tr_transforms)\n",
    "    files_tr_less_2 = data.Dataset(data = files_tr_less_2, transform = tr_transforms)\n",
    "    files_tr_less_3 = data.Dataset(data = files_tr_less_3, transform = tr_transforms)\n",
    "    files_tr_less_4 = data.Dataset(data = files_tr_less_4, transform = tr_transforms)\n",
    "    files_tr_less_5 = data.Dataset(data = files_tr_less_5, transform = tr_transforms)\n",
    "    \n",
    "    files_tr_more_1 = data.Dataset(data = files_tr_more_1, transform = tr_transforms)\n",
    "    files_tr_more_2 = data.Dataset(data = files_tr_more_2, transform = tr_transforms)\n",
    "    files_tr_more_3 = data.Dataset(data = files_tr_more_3, transform = tr_transforms)\n",
    "    files_tr_more_4 = data.Dataset(data = files_tr_more_4, transform = tr_transforms)\n",
    "    files_tr_more_5 = data.Dataset(data = files_tr_more_5, transform = tr_transforms)\n",
    "\n",
    "    nc_loader_1 = data.DataLoader(train_ds_nc_1, batch_size=1, shuffle=False, num_workers=8, pin_memory=True)\n",
    "    nc_loader_2 = data.DataLoader(train_ds_nc_2, batch_size=1, shuffle=False, num_workers=8, pin_memory=True)\n",
    "    nc_loader_3 = data.DataLoader(train_ds_nc_3, batch_size=1, shuffle=False, num_workers=8, pin_memory=True)\n",
    "    nc_loader_4 = data.DataLoader(train_ds_nc_4, batch_size=1, shuffle=False, num_workers=8, pin_memory=True)\n",
    "    nc_loader_5 = data.DataLoader(train_ds_nc_5, batch_size=1, shuffle=False, num_workers=8, pin_memory=True)\n",
    "    \n",
    "    less_loader_1 = data.DataLoader(files_tr_less_1, batch_size=1, shuffle=False, num_workers=8, pin_memory=True)\n",
    "    less_loader_2 = data.DataLoader(files_tr_less_2, batch_size=1, shuffle=False, num_workers=8, pin_memory=True)\n",
    "    less_loader_3 = data.DataLoader(files_tr_less_3, batch_size=1, shuffle=False, num_workers=8, pin_memory=True)\n",
    "    less_loader_4 = data.DataLoader(files_tr_less_4, batch_size=1, shuffle=False, num_workers=8, pin_memory=True)\n",
    "    less_loader_5 = data.DataLoader(files_tr_less_5, batch_size=1, shuffle=False, num_workers=8, pin_memory=True)\n",
    "    \n",
    "    more_loader_1 = data.DataLoader(files_tr_more_1, batch_size=1, shuffle=False, num_workers=8, pin_memory=True)\n",
    "    more_loader_2 = data.DataLoader(files_tr_more_2, batch_size=1, shuffle=False, num_workers=8, pin_memory=True)\n",
    "    more_loader_3 = data.DataLoader(files_tr_more_3, batch_size=1, shuffle=False, num_workers=8, pin_memory=True)\n",
    "    more_loader_4 = data.DataLoader(files_tr_more_4, batch_size=1, shuffle=False, num_workers=8, pin_memory=True)\n",
    "    more_loader_5 = data.DataLoader(files_tr_more_5, batch_size=1, shuffle=False, num_workers=8, pin_memory=True)\n",
    "    \n",
    "    print(\"loader is ver(train, val)\")\n",
    "\n",
    "    return [[nc_loader_1, nc_loader_2, nc_loader_3, nc_loader_4, nc_loader_5], [less_loader_1, less_loader_2, less_loader_3, less_loader_4, less_loader_5], [more_loader_1, more_loader_2, more_loader_3, more_loader_4, more_loader_5]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4369096b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_list = get_loader_for_direc_vector()\n",
    "\n",
    "nc_mean_gen_list = []\n",
    "less_mean_gen_list = []\n",
    "more_mean_gen_list = []\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"NC\")\n",
    "    dataset_nc = []\n",
    "    \n",
    "    for idx, batch_data in enumerate(loader_list[0][i]):\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            images = batch_data['image_train'].to('cuda')\n",
    "            coeffs3 = ptwt.wavedec3(images, pywt.Wavelet('haar'), level=1, mode='zero')\n",
    "            images = torch.cat((coeffs3[0], \n",
    "                                coeffs3[1]['aad'], \n",
    "                                coeffs3[1]['ada'], \n",
    "                                coeffs3[1]['add'], \n",
    "                                coeffs3[1]['daa'], \n",
    "                                coeffs3[1]['dad'], \n",
    "                                coeffs3[1]['dda'], \n",
    "                                coeffs3[1]['ddd']), dim=1)\n",
    "\n",
    "            latent = model.semantic_encoder(images)\n",
    "            dataset_nc.append(latent)\n",
    "            \n",
    "    print(f\"{i}th len : {len(loader_list[0][i])}\")\n",
    "    \n",
    "    print(\"LESS\")\n",
    "    dataset_less = []\n",
    "    \n",
    "    for idx, batch_data in enumerate(loader_list[1][i]):\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            images = batch_data['image_train'].to('cuda')\n",
    "            coeffs3 = ptwt.wavedec3(images, pywt.Wavelet('haar'), level=1, mode='zero')\n",
    "            images = torch.cat((coeffs3[0], \n",
    "                                coeffs3[1]['aad'], \n",
    "                                coeffs3[1]['ada'], \n",
    "                                coeffs3[1]['add'], \n",
    "                                coeffs3[1]['daa'], \n",
    "                                coeffs3[1]['dad'], \n",
    "                                coeffs3[1]['dda'], \n",
    "                                coeffs3[1]['ddd']), dim=1)\n",
    "            \n",
    "            latent = model.semantic_encoder(images)\n",
    "            dataset_less.append(latent)\n",
    "            \n",
    "    print(f\"{i}th len : {len(loader_list[1][i])}\")\n",
    "    \n",
    "    print(\"MORE\")\n",
    "    dataset_more = []\n",
    "    \n",
    "    for idx, batch_data in enumerate(loader_list[2][i]):\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            images = batch_data['image_train'].to('cuda')\n",
    "            coeffs3 = ptwt.wavedec3(images, pywt.Wavelet('haar'), level=1, mode='zero')\n",
    "            images = torch.cat((coeffs3[0], \n",
    "                                coeffs3[1]['aad'], \n",
    "                                coeffs3[1]['ada'], \n",
    "                                coeffs3[1]['add'], \n",
    "                                coeffs3[1]['daa'], \n",
    "                                coeffs3[1]['dad'], \n",
    "                                coeffs3[1]['dda'], \n",
    "                                coeffs3[1]['ddd']), dim=1)\n",
    "            \n",
    "            latent = model.semantic_encoder(images)\n",
    "            dataset_more.append(latent)\n",
    "                \n",
    "    print(f\"{i}th len : {len(loader_list[2][i])}\")\n",
    "\n",
    "    nc_mean_gen = mean_gen_latent(dataset_nc)\n",
    "    less_mean_gen = mean_gen_latent(dataset_less)\n",
    "    more_mean_gen = mean_gen_latent(dataset_more)\n",
    "    \n",
    "    nc_mean_gen_list.append(nc_mean_gen)\n",
    "    less_mean_gen_list.append(less_mean_gen)\n",
    "    more_mean_gen_list.append(more_mean_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29d118b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def a_direction(init_vector, fin_vector):\n",
    "    direction_vectors = []\n",
    "    \n",
    "    for init_vec, fin_vec in zip(init_vector, fin_vector):\n",
    "        direction_vector = fin_vec - init_vec\n",
    "        \n",
    "        # Normalize the direction vector using F.normalize\n",
    "        normalized_direction_vector = F.normalize(direction_vector, p=2, dim=1)  # Assuming you want to normalize across the last dimension\n",
    "        \n",
    "        direction_vectors.append(normalized_direction_vector)\n",
    "    return direction_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4260e18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NC_LESS\n",
    "nc_less_dir_list = []\n",
    "nc_less_dir_list.append(a_direction(nc_mean_gen_list[0], less_mean_gen_list[0]))\n",
    "nc_less_dir_list.append(a_direction(nc_mean_gen_list[1], less_mean_gen_list[1]))\n",
    "nc_less_dir_list.append(a_direction(nc_mean_gen_list[2], less_mean_gen_list[2]))\n",
    "nc_less_dir_list.append(a_direction(nc_mean_gen_list[3], less_mean_gen_list[3]))\n",
    "nc_less_dir_list.append(a_direction(nc_mean_gen_list[4], less_mean_gen_list[4]))\n",
    "\n",
    "nc_less_final_direction = []\n",
    "nc_less_final_direction.append((nc_less_dir_list[0][0][:,:] + nc_less_dir_list[1][0][:,:] + nc_less_dir_list[2][0][:,:] + nc_less_dir_list[3][0][:,:] + nc_less_dir_list[4][0][:,:])/5)\n",
    "nc_less_final_direction.append((nc_less_dir_list[0][1][:,:] + nc_less_dir_list[1][1][:,:] + nc_less_dir_list[2][1][:,:] + nc_less_dir_list[3][1][:,:] + nc_less_dir_list[4][1][:,:])/5)\n",
    "nc_less_final_direction.append((nc_less_dir_list[0][2][:,:] + nc_less_dir_list[1][2][:,:] + nc_less_dir_list[2][2][:,:] + nc_less_dir_list[3][2][:,:] + nc_less_dir_list[4][2][:,:])/5)\n",
    "nc_less_final_direction.append((nc_less_dir_list[0][3][:,:] + nc_less_dir_list[1][3][:,:] + nc_less_dir_list[2][3][:,:] + nc_less_dir_list[3][3][:,:] + nc_less_dir_list[4][3][:,:])/5)\n",
    "nc_less_final_direction.append((nc_less_dir_list[0][4][:,:] + nc_less_dir_list[1][4][:,:] + nc_less_dir_list[2][4][:,:] + nc_less_dir_list[3][4][:,:] + nc_less_dir_list[4][4][:,:])/5)\n",
    "\n",
    "#LESS_MORE\n",
    "less_more_dir_list = []\n",
    "less_more_dir_list.append(a_direction(less_mean_gen_list[0], more_mean_gen_list[0]))\n",
    "less_more_dir_list.append(a_direction(less_mean_gen_list[1], more_mean_gen_list[1]))\n",
    "less_more_dir_list.append(a_direction(less_mean_gen_list[2], more_mean_gen_list[2]))\n",
    "less_more_dir_list.append(a_direction(less_mean_gen_list[3], more_mean_gen_list[3]))\n",
    "less_more_dir_list.append(a_direction(less_mean_gen_list[4], more_mean_gen_list[4]))\n",
    "\n",
    "less_more_final_direction = []\n",
    "less_more_final_direction.append((less_more_dir_list[0][0][:,:] + less_more_dir_list[1][0][:,:] + less_more_dir_list[2][0][:,:] + less_more_dir_list[3][0][:,:] + less_more_dir_list[4][0][:,:])/5)\n",
    "less_more_final_direction.append((less_more_dir_list[0][1][:,:] + less_more_dir_list[1][1][:,:] + less_more_dir_list[2][1][:,:] + less_more_dir_list[3][1][:,:] + less_more_dir_list[4][1][:,:])/5)\n",
    "less_more_final_direction.append((less_more_dir_list[0][2][:,:] + less_more_dir_list[1][2][:,:] + less_more_dir_list[2][2][:,:] + less_more_dir_list[3][2][:,:] + less_more_dir_list[4][2][:,:])/5)\n",
    "less_more_final_direction.append((less_more_dir_list[0][3][:,:] + less_more_dir_list[1][3][:,:] + less_more_dir_list[2][3][:,:] + less_more_dir_list[3][3][:,:] + less_more_dir_list[4][3][:,:])/5)\n",
    "less_more_final_direction.append((less_more_dir_list[0][4][:,:] + less_more_dir_list[1][4][:,:] + less_more_dir_list[2][4][:,:] + less_more_dir_list[3][4][:,:] + less_more_dir_list[4][4][:,:])/5)\n",
    "\n",
    "#LESS_NC\n",
    "less_nc_dir_list = []\n",
    "less_nc_dir_list.append(a_direction(less_mean_gen_list[0], nc_mean_gen_list[0]))\n",
    "less_nc_dir_list.append(a_direction(less_mean_gen_list[1], nc_mean_gen_list[1]))\n",
    "less_nc_dir_list.append(a_direction(less_mean_gen_list[2], nc_mean_gen_list[2]))\n",
    "less_nc_dir_list.append(a_direction(less_mean_gen_list[3], nc_mean_gen_list[3]))\n",
    "less_nc_dir_list.append(a_direction(less_mean_gen_list[4], nc_mean_gen_list[4]))\n",
    "\n",
    "less_nc_final_direction = []\n",
    "less_nc_final_direction.append((less_nc_dir_list[0][0][:,:] + less_nc_dir_list[1][0][:,:] + less_nc_dir_list[2][0][:,:] + less_nc_dir_list[3][0][:,:] + less_nc_dir_list[4][0][:,:])/5)\n",
    "less_nc_final_direction.append((less_nc_dir_list[0][1][:,:] + less_nc_dir_list[1][1][:,:] + less_nc_dir_list[2][1][:,:] + less_nc_dir_list[3][1][:,:] + less_nc_dir_list[4][1][:,:])/5)\n",
    "less_nc_final_direction.append((less_nc_dir_list[0][2][:,:] + less_nc_dir_list[1][2][:,:] + less_nc_dir_list[2][2][:,:] + less_nc_dir_list[3][2][:,:] + less_nc_dir_list[4][2][:,:])/5)\n",
    "less_nc_final_direction.append((less_nc_dir_list[0][3][:,:] + less_nc_dir_list[1][3][:,:] + less_nc_dir_list[2][3][:,:] + less_nc_dir_list[3][3][:,:] + less_nc_dir_list[4][3][:,:])/5)\n",
    "less_nc_final_direction.append((less_nc_dir_list[0][4][:,:] + less_nc_dir_list[1][4][:,:] + less_nc_dir_list[2][4][:,:] + less_nc_dir_list[3][4][:,:] + less_nc_dir_list[4][4][:,:])/5)\n",
    "\n",
    "#MORE_LESS\n",
    "more_less_dir_list = []\n",
    "more_less_dir_list.append(a_direction(more_mean_gen_list[0], less_mean_gen_list[0]))\n",
    "more_less_dir_list.append(a_direction(more_mean_gen_list[1], less_mean_gen_list[1]))\n",
    "more_less_dir_list.append(a_direction(more_mean_gen_list[2], less_mean_gen_list[2]))\n",
    "more_less_dir_list.append(a_direction(more_mean_gen_list[3], less_mean_gen_list[3]))\n",
    "more_less_dir_list.append(a_direction(more_mean_gen_list[4], less_mean_gen_list[4]))\n",
    "\n",
    "more_less_final_direction = []\n",
    "more_less_final_direction.append((more_less_dir_list[0][0][:,:] + more_less_dir_list[1][0][:,:] + more_less_dir_list[2][0][:,:] + more_less_dir_list[3][0][:,:] + more_less_dir_list[4][0][:,:])/5)\n",
    "more_less_final_direction.append((more_less_dir_list[0][1][:,:] + more_less_dir_list[1][1][:,:] + more_less_dir_list[2][1][:,:] + more_less_dir_list[3][1][:,:] + more_less_dir_list[4][1][:,:])/5)\n",
    "more_less_final_direction.append((more_less_dir_list[0][2][:,:] + more_less_dir_list[1][2][:,:] + more_less_dir_list[2][2][:,:] + more_less_dir_list[3][2][:,:] + more_less_dir_list[4][2][:,:])/5)\n",
    "more_less_final_direction.append((more_less_dir_list[0][3][:,:] + more_less_dir_list[1][3][:,:] + more_less_dir_list[2][3][:,:] + more_less_dir_list[3][3][:,:] + more_less_dir_list[4][3][:,:])/5)\n",
    "more_less_final_direction.append((more_less_dir_list[0][4][:,:] + more_less_dir_list[1][4][:,:] + more_less_dir_list[2][4][:,:] + more_less_dir_list[3][4][:,:] + more_less_dir_list[4][4][:,:])/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcb9f0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import natsort\n",
    "import glob\n",
    "import SimpleITK as sitk\n",
    "\n",
    "def get_loader_for_manipulation():\n",
    "\n",
    "    NC_list = natsort.natsorted(glob.glob(\"/workspace/Ablation/ABLATION_PD/All_The_tSNE/MANIPULATION/NC/*.nii.gz\"))\n",
    "    LESS_list = natsort.natsorted(glob.glob(\"/workspace/Ablation/ABLATION_PD/All_The_tSNE/MANIPULATION/LESS/*.nii.gz\"))\n",
    "    MORE_list = natsort.natsorted(glob.glob(\"/workspace/Ablation/ABLATION_PD/All_The_tSNE/MANIPULATION/MORE/*.nii.gz\"))\n",
    "    \n",
    "    NC_patient_list = []\n",
    "    LESS_patient_list = []\n",
    "    MORE_patient_list = []\n",
    "    \n",
    "    for i in range(len(NC_list)):\n",
    "        NC_patient_list.append(NC_list[i].split('/')[-1].split(\"_centered\")[0])\n",
    "        LESS_patient_list.append(LESS_list[i].split('/')[-1].split(\"_centered\")[0])\n",
    "        MORE_patient_list.append(MORE_list[i].split('/')[-1].split(\"_centered\")[0])\n",
    "    \n",
    "    files_tr_nc = []\n",
    "    files_tr_less = []\n",
    "    files_tr_more = []\n",
    "\n",
    "    train_idx_nc = 0\n",
    "    train_idx_less = 0\n",
    "    train_idx_more = 0\n",
    "\n",
    "    for file_name in NC_list:\n",
    "        files_tr_nc.append({\"image_train\": file_name})\n",
    "        train_idx_nc += 1\n",
    "        \n",
    "    for file_name in LESS_list:\n",
    "        files_tr_less.append({\"image_train\": file_name})\n",
    "        train_idx_less += 1\n",
    "        \n",
    "    for file_name in MORE_list:\n",
    "        files_tr_more.append({\"image_train\": file_name})\n",
    "        train_idx_more += 1\n",
    "    \n",
    "    print(f\"Train [Total]  number = {train_idx_nc}, {train_idx_less}, {train_idx_more}\")\n",
    "\n",
    "    tr_transforms = transforms.Compose(\n",
    "        [\n",
    "            transforms.LoadImaged(keys=[\"image_train\"]),\n",
    "            transforms.EnsureChannelFirstd(keys=[\"image_train\"]),\n",
    "            transforms.Orientationd(keys=[\"image_train\"], axcodes=\"LPS\"),\n",
    "            transforms.ScaleIntensityRanged(keys=[\"image_train\"], a_min=0.0, a_max=22.0, b_min=0.0, b_max=1.0, clip=True),\n",
    "            transforms.EnsureTyped(keys=[\"image_train\"]),\n",
    "            transforms.ToTensord(keys=[\"image_train\"], track_meta=False)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # new_dataset -> Cachenew_dataset\n",
    "    train_ds_nc = data.Dataset(data = files_tr_nc, transform = tr_transforms)\n",
    "    files_tr_less = data.Dataset(data = files_tr_less, transform = tr_transforms)\n",
    "    files_tr_more = data.Dataset(data = files_tr_more, transform = tr_transforms)\n",
    "\n",
    "    nc_loader = data.DataLoader(train_ds_nc, batch_size=1, shuffle=False, num_workers=8, pin_memory=True)\n",
    "    less_loader = data.DataLoader(files_tr_less, batch_size=1, shuffle=False, num_workers=8, pin_memory=True)\n",
    "    more_loader = data.DataLoader(files_tr_more, batch_size=1, shuffle=False, num_workers=8, pin_memory=True)\n",
    "    \n",
    "    print(\"loader is ver(train, val)\")\n",
    "\n",
    "    return [nc_loader, less_loader, more_loader], [NC_patient_list, LESS_patient_list, MORE_patient_list]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4086b96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_list_init, [NC_ID, LESS_ID, MORE_ID] = get_loader_for_manipulation()\n",
    "\n",
    "print(\"NC\")\n",
    "tsne_dataset_nc_init = []\n",
    "\n",
    "for idx, batch_data in enumerate(loader_list_init[0]):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        images = batch_data['image_train'].to('cuda')\n",
    "        coeffs3 = ptwt.wavedec3(images, pywt.Wavelet('haar'), level=1, mode='zero')\n",
    "        images = torch.cat((coeffs3[0], \n",
    "                            coeffs3[1]['aad'], \n",
    "                            coeffs3[1]['ada'], \n",
    "                            coeffs3[1]['add'], \n",
    "                            coeffs3[1]['daa'], \n",
    "                            coeffs3[1]['dad'], \n",
    "                            coeffs3[1]['dda'], \n",
    "                            coeffs3[1]['ddd']), dim=1)\n",
    "        \n",
    "        latent = model.semantic_encoder(images)\n",
    "        tsne_dataset_nc_init.append(latent)\n",
    "  \n",
    "print(\"LESS\")\n",
    "\n",
    "tsne_dataset_less_init = []\n",
    "\n",
    "for idx, batch_data in enumerate(loader_list_init[1]):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        images = batch_data['image_train'].to('cuda')\n",
    "        coeffs3 = ptwt.wavedec3(images, pywt.Wavelet('haar'), level=1, mode='zero')\n",
    "        images = torch.cat((coeffs3[0], \n",
    "                            coeffs3[1]['aad'], \n",
    "                            coeffs3[1]['ada'], \n",
    "                            coeffs3[1]['add'], \n",
    "                            coeffs3[1]['daa'], \n",
    "                            coeffs3[1]['dad'], \n",
    "                            coeffs3[1]['dda'], \n",
    "                            coeffs3[1]['ddd']), dim=1)\n",
    "        \n",
    "        latent = model.semantic_encoder(images)\n",
    "        tsne_dataset_less_init.append(latent)\n",
    "        \n",
    "print(\"MORE\")\n",
    "\n",
    "tsne_dataset_more_init = []\n",
    "\n",
    "for idx, batch_data in enumerate(loader_list_init[2]):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        images = batch_data['image_train'].to('cuda')\n",
    "        coeffs3 = ptwt.wavedec3(images, pywt.Wavelet('haar'), level=1, mode='zero')\n",
    "        images = torch.cat((coeffs3[0], \n",
    "                            coeffs3[1]['aad'], \n",
    "                            coeffs3[1]['ada'], \n",
    "                            coeffs3[1]['add'], \n",
    "                            coeffs3[1]['daa'], \n",
    "                            coeffs3[1]['dad'], \n",
    "                            coeffs3[1]['dda'], \n",
    "                            coeffs3[1]['ddd']), dim=1)\n",
    "        \n",
    "        latent = model.semantic_encoder(images)\n",
    "        tsne_dataset_more_init.append(latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3376c02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "import ptwt\n",
    "import SimpleITK as sitk\n",
    "from generative.networks.schedulers import DDPMScheduler\n",
    "from generative.inferers import DiffusionInferer_ae\n",
    "\n",
    "scheduler = DDPMScheduler(num_train_timesteps=1000, \n",
    "                          schedule=\"linear_beta\", \n",
    "                          beta_start=0.0005, \n",
    "                          beta_end=0.0195)\n",
    "\n",
    "inferer = DiffusionInferer_ae(scheduler)\n",
    "\n",
    "for img_idx in range(5):\n",
    "    # NC to LESS\n",
    "    for factor in range(5):\n",
    "        factor = factor*0.5\n",
    "        print(f\"factor is {factor}\")\n",
    "        manipulated_vectors = [nc_vec + direction_vector * factor\n",
    "                            for nc_vec, direction_vector in zip(tsne_dataset_nc_init[img_idx], nc_less_final_direction)]\n",
    "        latent = manipulated_vectors\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            _, _, H, W, D = images.shape\n",
    "            image = torch.randn((1, 8, 96, 96, 48))\n",
    "            image = image.to(\"cuda\")\n",
    "            scheduler.set_timesteps(num_inference_steps=1000)\n",
    "            image_pred = inferer.sample(input_noise=image, \n",
    "                                        diffusion_model=model.unet, \n",
    "                                        scheduler=scheduler, \n",
    "                                        save_intermediates=False, \n",
    "                                        cond=latent)\n",
    "            rand_image = torch.randn((1, 1, 192, 192, 96))\n",
    "            coeffs3 = list(ptwt.wavedec3(rand_image, pywt.Wavelet('haar'), level=1, mode='zero'))\n",
    "\n",
    "            coeffs3[0] = image_pred[:,0:1,:,:,:]\n",
    "            coeffs3[1]['aad'] = image_pred[:,1:2,:,:,:]\n",
    "            coeffs3[1]['ada'] = image_pred[:,2:3,:,:,:]\n",
    "            coeffs3[1]['add'] = image_pred[:,3:4,:,:,:]\n",
    "            coeffs3[1]['daa'] = image_pred[:,4:5,:,:,:]\n",
    "            coeffs3[1]['dad'] = image_pred[:,5:6,:,:,:]\n",
    "            coeffs3[1]['dda'] = image_pred[:,6:7,:,:,:]\n",
    "            coeffs3[1]['ddd'] = image_pred[:,7:8,:,:,:]\n",
    "            coeffs3 = tuple(coeffs3)\n",
    "        \n",
    "            reconstruction = ptwt.waverec3(coeffs3, pywt.Wavelet(\"haar\"))\n",
    "            \n",
    "            pred_img = reconstruction.cpu().detach().numpy().transpose(0,4,3,2,1).squeeze()\n",
    "            save_pred = sitk.GetImageFromArray(pred_img)\n",
    "            img_id = NC_ID[img_idx]\n",
    "            sitk.WriteImage(save_pred, f\"/workspace/PD_SSL_ZOO/4_LATENT_MANIPULATION/nc_less_{img_id}_{factor}_pred.nii.gz\")\n",
    "            \n",
    "    #LESS to MORE\n",
    "    for factor in range(5):\n",
    "        factor = factor*0.5\n",
    "        print(f\"factor is {factor}\")\n",
    "        manipulated_vectors = [nc_vec + direction_vector * factor\n",
    "                            for nc_vec, direction_vector in zip(tsne_dataset_less_init[img_idx], less_more_final_direction)]\n",
    "        latent = manipulated_vectors\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            _, _, H, W, D = images.shape\n",
    "            image = torch.randn((1, 8, 96, 96, 48))\n",
    "            image = image.to(\"cuda\")\n",
    "            scheduler.set_timesteps(num_inference_steps=1000)\n",
    "            image_pred = inferer.sample(input_noise=image, \n",
    "                                        diffusion_model=model.unet, \n",
    "                                        scheduler=scheduler, \n",
    "                                        save_intermediates=False, \n",
    "                                        cond=latent)\n",
    "            rand_image = torch.randn((1, 1, 192, 192, 96))\n",
    "            coeffs3 = list(ptwt.wavedec3(rand_image, pywt.Wavelet('haar'), level=1, mode='zero'))\n",
    "            \n",
    "            coeffs3[0] = image_pred[:,0:1,:,:,:]\n",
    "            coeffs3[1]['aad'] = image_pred[:,1:2,:,:,:]\n",
    "            coeffs3[1]['ada'] = image_pred[:,2:3,:,:,:]\n",
    "            coeffs3[1]['add'] = image_pred[:,3:4,:,:,:]\n",
    "            coeffs3[1]['daa'] = image_pred[:,4:5,:,:,:]\n",
    "            coeffs3[1]['dad'] = image_pred[:,5:6,:,:,:]\n",
    "            coeffs3[1]['dda'] = image_pred[:,6:7,:,:,:]\n",
    "            coeffs3[1]['ddd'] = image_pred[:,7:8,:,:,:]\n",
    "            coeffs3 = tuple(coeffs3)\n",
    "        \n",
    "            reconstruction = ptwt.waverec3(coeffs3, pywt.Wavelet(\"haar\"))\n",
    "            \n",
    "            pred_img = reconstruction.cpu().detach().numpy().transpose(0,4,3,2,1).squeeze()\n",
    "            save_pred = sitk.GetImageFromArray(pred_img)\n",
    "            img_id = LESS_ID[img_idx]\n",
    "            sitk.WriteImage(save_pred, f\"/workspace/PD_SSL_ZOO/4_LATENT_MANIPULATION/less_more_{img_id}_{factor}_pred.nii.gz\")\n",
    "\n",
    "    # #LESS to NC\n",
    "    for factor in range(5):\n",
    "        factor = factor*0.5\n",
    "        print(f\"factor is {factor}\")\n",
    "        manipulated_vectors = [nc_vec + direction_vector * factor\n",
    "                            for nc_vec, direction_vector in zip(tsne_dataset_less_init[img_idx], less_nc_final_direction)]\n",
    "        latent = manipulated_vectors\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            _, _, H, W, D = images.shape\n",
    "            image = torch.randn((1, 8, 96, 96, 48))\n",
    "            image = image.to(\"cuda\")\n",
    "            scheduler.set_timesteps(num_inference_steps=1000)\n",
    "            image_pred = inferer.sample(input_noise=image, \n",
    "                                        diffusion_model=model.unet, \n",
    "                                        scheduler=scheduler, \n",
    "                                        save_intermediates=False, \n",
    "                                        cond=latent)\n",
    "            rand_image = torch.randn((1, 1, 192, 192, 96))\n",
    "            coeffs3 = list(ptwt.wavedec3(rand_image, pywt.Wavelet('haar'), level=1, mode='zero'))\n",
    "            \n",
    "            coeffs3[0] = image_pred[:,0:1,:,:,:]\n",
    "            coeffs3[1]['aad'] = image_pred[:,1:2,:,:,:]\n",
    "            coeffs3[1]['ada'] = image_pred[:,2:3,:,:,:]\n",
    "            coeffs3[1]['add'] = image_pred[:,3:4,:,:,:]\n",
    "            coeffs3[1]['daa'] = image_pred[:,4:5,:,:,:]\n",
    "            coeffs3[1]['dad'] = image_pred[:,5:6,:,:,:]\n",
    "            coeffs3[1]['dda'] = image_pred[:,6:7,:,:,:]\n",
    "            coeffs3[1]['ddd'] = image_pred[:,7:8,:,:,:]\n",
    "            coeffs3 = tuple(coeffs3)\n",
    "        \n",
    "            reconstruction = ptwt.waverec3(coeffs3, pywt.Wavelet(\"haar\"))\n",
    "            \n",
    "            pred_img = reconstruction.cpu().detach().numpy().transpose(0,4,3,2,1).squeeze()\n",
    "            save_pred = sitk.GetImageFromArray(pred_img)\n",
    "            img_id = LESS_ID[img_idx]\n",
    "            sitk.WriteImage(save_pred, f\"/workspace/PD_SSL_ZOO/4_LATENT_MANIPULATION/less_nc_{img_id}_{factor}_pred.nii.gz\")\n",
    "\n",
    "    #MORE to LESS\n",
    "    for factor in range(5):\n",
    "        factor = factor*0.5\n",
    "        print(f\"factor is {factor}\")\n",
    "        manipulated_vectors = [nc_vec + direction_vector * factor\n",
    "                            for nc_vec, direction_vector in zip(tsne_dataset_more_init[img_idx], more_less_final_direction)]\n",
    "        latent = manipulated_vectors\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            _, _, H, W, D = images.shape\n",
    "            image = torch.randn((1, 8, 96, 96, 48))\n",
    "            image = image.to(\"cuda\")\n",
    "            scheduler.set_timesteps(num_inference_steps=1000)\n",
    "            image_pred = inferer.sample(input_noise=image, \n",
    "                                        diffusion_model=model.unet, \n",
    "                                        scheduler=scheduler, \n",
    "                                        save_intermediates=False, \n",
    "                                        cond=latent)\n",
    "            rand_image = torch.randn((1, 1, 192, 192, 96))\n",
    "            coeffs3 = list(ptwt.wavedec3(rand_image, pywt.Wavelet('haar'), level=1, mode='zero'))\n",
    "            \n",
    "            coeffs3[0] = image_pred[:,0:1,:,:,:]\n",
    "            coeffs3[1]['aad'] = image_pred[:,1:2,:,:,:]\n",
    "            coeffs3[1]['ada'] = image_pred[:,2:3,:,:,:]\n",
    "            coeffs3[1]['add'] = image_pred[:,3:4,:,:,:]\n",
    "            coeffs3[1]['daa'] = image_pred[:,4:5,:,:,:]\n",
    "            coeffs3[1]['dad'] = image_pred[:,5:6,:,:,:]\n",
    "            coeffs3[1]['dda'] = image_pred[:,6:7,:,:,:]\n",
    "            coeffs3[1]['ddd'] = image_pred[:,7:8,:,:,:]\n",
    "            coeffs3 = tuple(coeffs3)\n",
    "        \n",
    "            reconstruction = ptwt.waverec3(coeffs3, pywt.Wavelet(\"haar\"))\n",
    "            \n",
    "            pred_img = reconstruction.cpu().detach().numpy().transpose(0,4,3,2,1).squeeze()\n",
    "            save_pred = sitk.GetImageFromArray(pred_img)\n",
    "            img_id = MORE_ID[img_idx]\n",
    "            sitk.WriteImage(save_pred, f\"/workspace/PD_SSL_ZOO/4_LATENT_MANIPULATION/more_less_{img_id}_{factor}_pred.nii.gz\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
