{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train [Total]  number =  30\n",
      "loader is ver (train)\n"
     ]
    }
   ],
   "source": [
    "from monai import data, transforms\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import natsort\n",
    "import SimpleITK as sitk\n",
    "\n",
    "def get_loader():\n",
    "    train_real = natsort.natsorted(glob.glob(f'/workspace/PD_SSL_ZOO/3_RECONSTRUCTION/DATA/*.nii.gz'))[:] #ALL -> 2125 or 2130\n",
    "\n",
    "    print(\"Train [Total]  number = \", len(train_real))\n",
    "\n",
    "    files_tr = [img_tr for img_tr in zip(train_real)]\n",
    "\n",
    "    tr_transforms = transforms.Compose(\n",
    "        [\n",
    "            transforms.LoadImage(image_only=True),\n",
    "            transforms.EnsureChannelFirst(),\n",
    "            transforms.Orientation(axcodes=\"LPS\"),\n",
    "            transforms.EnsureType(),\n",
    "            transforms.ToTensor(track_meta=False)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # new_dataset -> Cachenew_dataset\n",
    "    train_ds = data.Dataset(data = files_tr, transform = tr_transforms)\n",
    "\n",
    "    train_loader = data.DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        pin_memory=False\n",
    "        # persistent_workers=True,\n",
    "    )\n",
    "\n",
    "    print(\"loader is ver (train)\")\n",
    "\n",
    "    loader = train_loader\n",
    "\n",
    "    return loader, train_real\n",
    "loader = get_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "    \n",
    "from generative.networks.nets.diffusion_model_aniso_unet_AE_official import DiffusionModelUNet_aniso_AE, DiffusionModelEncoder_ansio\n",
    "class DIF_oriAE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.unet =  DiffusionModelUNet_aniso_AE(spatial_dims=3,\n",
    "                                                in_channels=8, #wavelet mode\n",
    "                                                out_channels=8, #wavelet mode\n",
    "                                                num_channels=[128,128,256,256,512],\n",
    "                                                attention_levels=[False,False,False,False,True],\n",
    "                                                num_head_channels=[0,0,0,0,64],\n",
    "                                                norm_num_groups=32,\n",
    "                                                use_flash_attention=True,\n",
    "                                                iso_conv_down=(False, True, True, True, None),\n",
    "                                                iso_conv_up=(True, True, True, False, None),\n",
    "                                                num_res_blocks=2)\n",
    "\n",
    "\n",
    "        self.semantic_encoder = DiffusionModelEncoder_ansio(spatial_dims=3,\n",
    "                                                            in_channels=8,\n",
    "                                                            out_channels=8,\n",
    "                                                            num_channels=[128,256,256,512],\n",
    "                                                            attention_levels=[False,False,False,False],\n",
    "                                                            num_head_channels=[0,0,0,0],\n",
    "                                                            norm_num_groups=32,\n",
    "                                                            iso_conv_down=(False, True, True, True),\n",
    "                                                            num_res_blocks=(2,2,2,2))\n",
    "\n",
    "def filter_ema_keys(checkpoint):\n",
    "    ema_model_state_dict = {key.replace('ema_model.', ''): value \n",
    "                            for key, value in checkpoint.items() \n",
    "                            if 'online_model' not in key}\n",
    "    del ema_model_state_dict['initted']\n",
    "    del ema_model_state_dict['step']\n",
    "    \n",
    "    return ema_model_state_dict\n",
    "    \n",
    "def save_image(pred, path):\n",
    "    pred_img = pred.cpu().detach().numpy().transpose(0,4,3,2,1).squeeze()\n",
    "    save_pred = sitk.GetImageFromArray(pred_img)\n",
    "    sitk.WriteImage(save_pred, path)\n",
    "    \n",
    "model = DIF_oriAE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generative.inferers import DiffusionInferer_ae\n",
    "from generative.networks.schedulers import DDPMScheduler\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import ptwt\n",
    "import pywt\n",
    "\n",
    "ckpt_path = '/workspace/PD_SSL_ZOO/2_DOWNSTREAM/WEIGHTS/1_HWDAE.pt'\n",
    "ckpt = torch.load(ckpt_path, map_location='cpu')\n",
    "checkpoint = ckpt['ema']\n",
    "new_ckpt = filter_ema_keys(checkpoint)\n",
    "model.load_state_dict(new_ckpt)\n",
    "print(f\"ckpt_path : {ckpt_path}\")\n",
    "\n",
    "scheduler = DDPMScheduler(num_train_timesteps=1000, \n",
    "                          schedule=\"linear_beta\", \n",
    "                          beta_start=0.0005, \n",
    "                          beta_end=0.0195)\n",
    "\n",
    "inferer = DiffusionInferer_ae(scheduler)\n",
    "\n",
    "model.to('cuda')\n",
    "loader, train_list = get_loader()\n",
    "\n",
    "for idx, batch_data in enumerate(loader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        images = batch_data.to('cuda')\n",
    "        coeffs3 = ptwt.wavedec3(images, pywt.Wavelet('haar'), level=1, mode='zero')\n",
    "        images = torch.cat((coeffs3[0], \n",
    "                        coeffs3[1]['aad'], \n",
    "                        coeffs3[1]['ada'], \n",
    "                        coeffs3[1]['add'], \n",
    "                        coeffs3[1]['daa'], \n",
    "                        coeffs3[1]['dad'], \n",
    "                        coeffs3[1]['dda'], \n",
    "                        coeffs3[1]['ddd']), dim=1)\n",
    "        \n",
    "        timesteps = torch.randint(0, inferer.scheduler.num_train_timesteps, (images.shape[0],), device=images.device).long()\n",
    "        noise = torch.randn_like(images).to('cuda')\n",
    "\n",
    "        latent = model.semantic_encoder(images)\n",
    "\n",
    "    _, _, H, W, D = images.shape\n",
    "    # Sampling image during training\n",
    "    image = torch.randn((1, 8, H, W, D))\n",
    "    image = image.to(\"cuda\")\n",
    "    scheduler.set_timesteps(num_inference_steps=1000)\n",
    "    image_pred = inferer.sample(input_noise=image, \n",
    "                                diffusion_model=model.unet, \n",
    "                                scheduler=scheduler, \n",
    "                                save_intermediates=False,\n",
    "                                cond=latent)\n",
    "        \n",
    "    coeffs3[0] = image_pred[:,0:1,:,:,:]\n",
    "    coeffs3[1]['aad'] = image_pred[:,1:2,:,:,:]\n",
    "    coeffs3[1]['ada'] = image_pred[:,2:3,:,:,:]\n",
    "    coeffs3[1]['add'] = image_pred[:,3:4,:,:,:]\n",
    "    coeffs3[1]['daa'] = image_pred[:,4:5,:,:,:]\n",
    "    coeffs3[1]['dad'] = image_pred[:,5:6,:,:,:]\n",
    "    coeffs3[1]['dda'] = image_pred[:,6:7,:,:,:]\n",
    "    coeffs3[1]['ddd'] = image_pred[:,7:8,:,:,:]\n",
    "    \n",
    "    reconstruction_ema = ptwt.waverec3(coeffs3, pywt.Wavelet(\"haar\"))       \n",
    "\n",
    "    pred_path = train_list[idx].replace(\"DATA\", \"1_HWDAE\")\n",
    "    \n",
    "    save_image(reconstruction_ema, pred_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
